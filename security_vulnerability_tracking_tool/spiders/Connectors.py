import scrapy
import pandas as pd
from pandas import ExcelWriter

class ConnectersSpider(scrapy.Spider):
    name = 'connectors'
    allowed_domains = ['tomcat.apache.org/security-jk.html']
    start_urls = ['https://tomcat.apache.org/security-jk.html']

    def parse(self, response):
        impact_Rating = response.xpath('//*[@id="content"]/div/p/strong/text()').re('^[LIMC]')
        advisory = response.xpath('//*[@id="content"]/div/p/strong/text()').re(' .*')
            #not multiline add it later re.MULTILINE
        cve_Id  = response.xpath('//*[@id="content"]/div/p[1]/a[contains(text(),"CVE")]/text()').extract()
        versions_Affected=response.xpath('//p[contains(text(),"Affects")]/text()[1]').re(' .*')

        modified_Impact_name=[]
        for item in impact_Rating:
            if item == 'L':
                item = 'low'
            if item == 'I':
                item = 'important'
            if item == 'M':
                item = 'moderate'
            if item == 'C':
                item = 'critical'
            modified_Impact_name.append(item)
        impact_Rating=modified_Impact_name


        try:
            data = {'impact_Rating':impact_Rating,'Advisory':advisory,"CVE-Id":cve_Id ,"versions_Affected":versions_Affected
                     }
            df = pd.DataFrame(data,columns=['impact_Rating',"CVE-Id",'Advisory',
                    "versions_Affected"])
            writer = ExcelWriter("Connectors"+".xlsx")
            print(writer)
            df.to_excel(writer,'CVE Details',index=False)
            writer.save()

        except Exception as e:
            print("type error: " + str(e))

        pass
