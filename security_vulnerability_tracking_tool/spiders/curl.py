# -*- coding: utf-8 -*-
import scrapy
import pandas as pd
from pandas import ExcelWriter

class CurlSpider(scrapy.Spider):
    name = 'curl'
    allowed_domains = ['curl.haxx.se/docs/security.html']
    start_urls = ['https://curl.haxx.se/docs/security.html']

    def parse(self, response):
        #impact_Rating = response.xpath('//table/tbody/tr/td[2]/a/text()').extract()
        date = response.xpath('//tr/td[3]/text()').extract()
        advisory =  response.xpath('//tr/td[2]/a/text()').extract()
        cve_Id  = response.xpath('//tr/td[6]//text()').extract()
        versions_Affected  =response.xpath('//tr/td[4]/a/text()').extract()
        versions_Affected2 =response.xpath('//tr/td[5]/a/text()').extract()
        cwe = response.xpath('//tr/td[7]/a/text()').extract()

        try:
            data = {"Date":date,"Advisory":advisory,"Cve_Id":cve_Id,"Versions_Affected":versions_Affected,
                    "Affected_upto":versions_Affected2,"Cwe":cwe}
            df = pd.DataFrame(data,columns=["Cve_Id","Advisory","Date","Versions_Affected",
                    "Affected_upto"])
            writer = ExcelWriter("curl"+".xlsx")
            df.to_excel(writer,'CVE Details',index=False)
            writer.save()

        except Exception as e:
            print("type error: " + str(e))

        pass
